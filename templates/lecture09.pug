doctype html
- var bgr = './static/slides/bgr/bgr_09.jpg'
include ./partial/header.pug
include ./partial/title.pug
include ./partial/containers.pug
include ./partial/texts.pug

+header('MI-APH - Lecture09', 'Lecture 9: Game AI', 'lecture09')
// ===================================================== SLIDES =====================================================
.reveal
  .slides
    // ============================================================
    +msection(bgr)
      .lecture-logo.mb80
        include ../static/slides/svg/lecture09/lecture09_logo.svg
      +title('Game AI')
    // ============================================================
    +mcontainer(bgr)    
      h3 Literature
      ul
        li
          a(href='https://www.amazon.com/Programming-Example-Wordware-Developers-Library/dp/1556220782') Buckland, Mat. 2005. Programming Game AI by Example
        li
          a(href='https://www.amazon.com/Artificial-Intelligence-Modern-Approach-3rd/dp/0136042597') Russell, Stuart. 2010. Artificial Intelligence: A Modern Approach (3rd ed.)
      .center-content
        .w1000
          img(src!='../static/slides/images/lecture09/book_ai.jpg')
    // ============================================================
    +chapter(bgr, 'Game AI overview')
    // ============================================================
    +mframeGreen(bgr, 'Artificial intelligence in games')
      ul
        li a broad set of principles that generate behaviors, providing an 
          span.highlight illusion of intelligence
        li the second greatest challenge after graphics
        li.highlight do not mistake for the academic AI
      ul
        li.highlight-third If you have a stunning FPS game, who cares whether or not the NPCs really work together as a team as long as the player believes they actually do?</i>
      .columns-3.tcenter.mt20
        div
          img.h500(src='../static/slides/images/lecture09/ai_in_games_1.jpg')
        div
          img.h500(src='../static/slides/images/lecture09/ai_in_games_2.jpg')
        div
          img.h500(src='../static/slides/images/lecture09/ai_in_games_3.jpg')
    // ============================================================
    +mframeGreen(bgr, 'AI techniques')
      .tcenter
        img.h900(src='../static/slides/svg/lecture09/ai_techniques_list.svg')
    // ============================================================
    +mframe-statement(bgr, 'AI techniques')
       .tcenter
          img.h300(src='../static/slides/svg/lecture09/ai_techniques.svg')
    // ============================================================
    +mframe(bgr, 'AI in game history')(class='space-vert-m')
      h4 Doom 1 (1993)
      ul
        li monster infighting (two AI characters encounter each other)
      h4 Age of Empires (1997)
      ul
        li AI is smart enough to find and revisit other kingdoms, poor in self-defense, though
      h4 Half-life (1998)
      ul
        li monsters can hear and track players, flee when getting defeated etc.
      h4 F.E.A.R. (2005)
      ul
        li tactical coordinating with squad members, suppression fire, blind fire
      h4 ARMA 3 (2013)
      ul
        li efficient issue ordering, situation-based decisions, retreats, ambush
      h4 DOTA 2 (2013)
      ul
        li OpenAI bot (since 2017) has beaten some of the greatest players
    // ============================================================
    +chapter(bgr, 'Navigation')
    // ============================================================
    +mframeGreen(bgr, 'Navigation')
      ul
        li navigation is essential for AI to accomplish tasks
          ul
            li local navigation in an environment (collision avoidance, ORCA)
            li global navigation (pathfinding)
            li navigation in a graph of case-based tasks
            li choreographed formations
      .tcenter
        img.h500(src='../static/slides/images/lecture09/navigation.gif')
    // ============================================================
    +mframeGreen(bgr, 'Navigation graph')
      ul
        li.highlight-sec abstraction of all locations in a game environment the agents may visit
        li enables game agents to calculate paths that avoid water, prefer traveling on roads to forest,...
        li may carry additional attributes (functions, type of a crossing etc.)
        li.highlight-sec waypoint-based, mesh-based, grid-based
      ul
        li 
          span.highlight Node  
          |- position of a key area within the environment
        li
          span.highlight Edge 
          |- connection between those points
      .tcenter
        img.h550(src='../static/slides/svg/lecture09/navigation_graph.svg')
    // ============================================================
    +mframeOrange(bgr, 'Navigation graph')
      h4 Waypoint-based
      ul
        li level designer places waypoints that are later linked up
      .tcenter
        img.h250(src='../static/slides/svg/lecture09/navigation_graph_waypoints.svg')
      h4 Mesh-based
      ul
        li created from a polygonal representation of the environment's floor
        li describes walkable areas
      .columns-2
        .tcenter
          img.h250(src='../static/slides/svg/lecture09/navigation_graph_meshbased_1.svg')
        .tcenter
          img.h350(src='../static/slides/svg/lecture09/navigation_graph_meshbased_2.svg')
    // ============================================================
    +mframe(bgr, 'Example: Unity mesh editor')
      .tcenter
        img.h900(src='../static/slides/images/lecture09/unity_nav_mesh.jpg')
    // ============================================================
    +mframe(bgr, 'Example: Counter-strike')
      .columns-2
        .tcenter
          img.h450(src='../static/slides/images/lecture09/cstrike_01.jpg')
        .tcenter
          img.h450(src='../static/slides/images/lecture09/cstrike_02.jpg')
      .columns-2
        .tcenter
          img.h450(src='../static/slides/images/lecture09/cstrike_03.jpg')
        .tcenter
          img.h450(src='../static/slides/images/lecture09/cstrike_04.jpg')
    // ============================================================
    +mframeOrange(bgr, 'Navigation graph')
      h4 Grid-based
      ul
        li created by superimposing a grid over a game environment
        li
          span.highlight-sec traversability flag 
          | indicates whether the cell is traversable or not
        li connection geometries: 
          span.highlight-sec tile, octile, hex
        li reflecting environmental changes = recalculation of the traversability flag
      .tcenter
        img.h300(src='../static/slides/svg/lecture09/navigation_graph_gridbased_types.svg')
      .tcenter
        img.h300(src='../static/slides/svg/lecture09/navigation_graph_gridbased_traversability.svg')
    // ============================================================
    +mframe(bgr, 'Example: Connection geometry')
      .tcenter
        img.h400(src='../static/slides/svg/lecture09/navigation_graph_gridbased_types.svg')
      .columns-3
        figure
          img.h400(src='../static/slides/images/lecture09/cgeometry_pokemon.jpg')
          p Pok√©mon series
        figure
          img.h400(src='../static/slides/images/lecture09/cgeometry_openttdmap.jpg')
          p OpenTTD
        figure
          img.h400(src='../static/slides/images/lecture09/cgeometry_heroes3.jpg')
          p Heroes of M&M
    // ============================================================
    +mframe(bgr, 'Combined geometry')
      ul
        li units can move in any direction, static objects are located on a grid
      .tcenter
        figure
          img.h750(src='../static/slides/images/lecture09/connection_geometry_sc.jpg')
          p Starcraft II
    // ============================================================
    +mframeGreen(bgr, 'Pathfinding')
      .bottom-content.justify-right.fill
        img.h600(src='../static/slides/images/lecture09/pathfinding.gif')
      h4 Properties
      ul
        li
          +strtext2('', 'completeness', '- find a solution')
        li
          +strtext2('', 'optimality', '- quality of the solution returned')
        li
          +strtext2('', 'smoothing', '- whether the agent could move along the path smoothly')
          ul
            li steering behavior can be used to smooth the path
      h4 Environment type
      ul
        li
          +strtext2('', 'static', '- the map never changes during the gameplay')
        li
          +strtext2('', 'dynamic', '- areas previously traversable can be obstructed later')
        li the higher the dynamicity, the higher the number of replanning
      h4 NPC movement
      ol
        li find the closest graph node to the NPC's current location: A
        li find the closest graph node to the target location: B
        li find path from A to B
        li move to A
        li move along the path to B
        li move from B to target location
    // ============================================================
    +mframeOrange(bgr, 'Pathfinding algorithms')(class='line-sm')
      h4 Uniformed graph searches
      ul
        li searches a graph without regard to any associated edge cost
        li
          span.highlight-sec DFS (depth-first search)
          ul
            li searches by moving as deep into the graph as possible
            li doesn't guarantee to find the best path
        li
          span.highlight-sec BFS (breadth-first search)
          ul
            li fans out from the source node, always finds the best path
      h4 Cost-based graph searches
      ul
        li
          span.highlight-sec Dijkstra's Algorithm
          ul
            li explores every node in the graph and finds the shortest path from the start node to every other node in the graph
            li uses 
              span.highlight-sec CSF (cost-so-far) 
              | metric
            li explores many unnecessary nodes
        li
          span.highlight-sec A* (Dijkstra with a Twist)
          ul
            li extension of Dijkstra, first described in 1968
            li main difference: augmentation of the CSF value with a 
              span.highlight-sec heuristic value
    // ============================================================
    +mframeOrange(bgr, 'A*')
      ul
        li improved Dijkstra by an estimate of the cost to the target from each node
        li Cost 
          include ../build_pre/equations/lecture09/astar_01.svg
          |, where 
          include ../build_pre/equations/lecture09/astar_02.svg
          |&nbsp;is the cost-so-far and 
          include ../build_pre/equations/lecture09/astar_03.svg
          |&nbsp;is the heuristic estimate
        li 
          +strtext2('', 'Heuristics:', 'Euclidean, Manhattan, adaptive (penalty for direction change)')
          ul
            li Manhattan distance will work if almost no obstacles appear
      ul
        li 
          span.highlight Improvements
          ul
            li preprocess the map, calculate universal paths
            li mark tiles which cannot lead anywhere as dead-ends
            li limit the search space
      .tcenter
        img.h400(src='../static/slides/svg/lecture09/astar.svg')
    // ============================================================
    +mframeOrange(bgr, 'Pathfinding algorithms: comparison')
      ul
        li breadth-first search ignores costs
        li Dijkstra ignores position of the target
        li A* takes into account both of them
      .tcenter.mt20
        img.h600(src='../static/slides/svg/lecture09/pathfinding_comparison.svg')
    // ============================================================
    +mframeGreen(bgr, 'HPA*: Hierarchical pathfinding A*')
      ul
        li uses a fixed-size clustering abstraction (problem subdivision)
        li several superimposed navigation graphs of different granularities
        li divides the navgraphs into regions
        li 
          +strtext('', 'gate', '- longest obstacle-free segment along a border')
        li transition across clusters are connected by intra-edges
        li.highlight fast enough for most games
      ul
        li 
          +strtext('', '3 stages:','build an abstract graph, search the abstract graph for an abstract path, refine the abstract path into a low-level path')
      .tcenter
        img.h400(src='../static/slides/svg/lecture09/pathfinding_hpa.svg')
    // ============================================================
    +mframe(bgr, 'Example: OpenTTD')
      .top-content.justify-left.fill
        img.h100(src='../static/slides/images/lecture09/openttd.jpg')
      .top-content.justify-left.fill
        .w60.openttd
          ul
            li Business simulator, derived from Transport Tycoon Deluxe
            li 
              span.highlight many challenges to AI
              ul
                li management over particular transport types
                li financial issues handling (loan control)
                li maintenance and vehicle replacement
                li acceleration model
                li upgrades, road extending
                li pathfinding, partial resuability of existing roads
                li vehicle utilization, failures, traffic
    // ============================================================
    +mframeGreen(bgr, 'OpentTD AI')
      h4 PathZilla AI
      ul
        li advanced graph theory
        li Delaunay Triangulation
        li roads based on minimum spanning tree
        li queue of planned actions
      h4 trAIns
      ul
        li most scientific approach, evolved from a research project in 2008
        li double railways support
        li concentration of production
      h4 AdmiralAI
      ul
        li attempt to implement as many features from game API as possible
        li the oldest and most comprehensive AI for OpenTTD
      h4 NoCAB
      ul
        li very fast network development and company value grow
        li custom A* implementation designed for speed
        li can upgrade vehicles
    // ============================================================
    +mframe(bgr, 'Example: Pathzilla road analysis')
      .columns-4
        figure
          img.h300(src='../static/slides/images/lecture09/pathzilla_01.jpg')
          p
        figure
          img.h300(src='../static/slides/images/lecture09/pathzilla_02.jpg')
          p Triangulation
        figure
          img.h300(src='../static/slides/images/lecture09/pathzilla_03.jpg')
          p Shortest path tree
        figure
          img.h300(src='../static/slides/images/lecture09/pathzilla_04.jpg')
          p Min spanning tree
      .columns-4
        figure
          img.h300(src='../static/slides/images/lecture09/pathzilla_05.jpg')
          p Planning graph
        figure
          img.h300(src='../static/slides/images/lecture09/pathzilla_06.jpg')
          p 
        figure
          img.h300(src='../static/slides/images/lecture09/pathzilla_07.jpg')
          p 
        figure
          img.h300(src='../static/slides/images/lecture09/pathzilla_08.jpg')
          p Final road network
    // ============================================================
    +chapter(bgr, 'Basic AI techniques')
    // ============================================================
    +mframeOrange(bgr, 'Scripting')
      .bottom-content.justify-right.fill
        img.h550(src='../static/slides/images/lecture09/scripting.gif')
      ul
        li 
          +strtext('', 'IF-THIS-THEN-THAT','approach')
        li AI behavior is completely hardcoded
        li.upside simple, easy to debug, easy to extend if programmed properly
        li.downside human player should behave as the developers expect
        li.downside good scripting behavior must cover a large amount of situations
      div.code
        include ../static/slides/snippets/lecture09/doom_chase.html
    // ============================================================
    +mframeOrange(bgr, 'Finite state machine')
      ul
        li the oldest and most commonly used formalism to model game AIs
        li useful for an entity whose behavior changes based on an internal state that can be divided<br> into small number of distinct options
        li each game entity can be in exactly one of a finite number of states at any time
      ul
        li
          span.highlight Definition
          ul
            li quadruple 
              include ../build_pre/equations/lecture09/fsm_01.svg
            li 
              include ../build_pre/equations/lecture09/fsm_02.svg
              |&nbsp;is a finite, non-empty set of states
            li
              include ../build_pre/equations/lecture09/fsm_03.svg
              |&nbsp;is a finite set of inputs
            li
              include ../build_pre/equations/lecture09/fsm_04.svg
              |&nbsp;is the state-transition function
            li
              include ../build_pre/equations/lecture09/fsm_05.svg
              |&nbsp;is an initial state, 
              include ../build_pre/equations/lecture09/fsm_06.svg
        li.mt40 can be implemented via polymorphism or a state transition table
        li.downside unmanageable for large complex systems, leading to transition explosion
    // ============================================================
    +mframeGreen(bgr, 'Example: Pacman FSM')
      .bottom-content.justify-right
        img.h150(src='../static/slides/images/lecture09/fsm_pacman.png')
      .tcenter
        img.h750(src='../static/slides/svg/lecture09/fsm_pacman.svg')
    // ============================================================
    +mframe(bgr, 'Example: Pacman transition table')
      .center-content
        table.flat
          tr
            th State
            th Transition
            th Condition
          tr
            td Wander the maze
            td Chase pacman
            td Spot Pacman
          tr
            td Wander the maze
            td Flee Pacman
            td PowerPellet eaten
          tr
            td Chase Pacman
            td Wander the maze
            td Lose Pacman
          tr
            td Chase Pacman
            td Flee Pacman
            td PowerPellet eaten
          tr
            td Flee Pacman
            td Return to Base
            td Eaten by Pacman
          tr
            td Flee Pacman
            td Wander the maze
            td PowerPellet expires
          tr
            td Return to Base
            td Wander the maze
            td Reach Central base
    // ============================================================
    +mframe(bgr, 'Example: Warcraft Doomguard')
      .bottom-content.justify-right
        img.h450(src='../static/slides/images/lecture09/fsm_doomguard.png')
      .tcenter
        img.h850(src='../static/slides/svg/lecture09/fsm_guardian.svg')
    // ============================================================
    +mframe(bgr, 'Example: Warcraft Doomguard')
      .bottom-content.justify-right
        img.h450(src='../static/slides/images/lecture09/fsm_doomguard.png')
      ul
        li let's add an ability to fall asleep
      .tcenter
        img.h800(src='../static/slides/svg/lecture09/fsm_guardian_2.svg')
    // ============================================================
    +mframeOrange(bgr, 'Hierarchical state machine')
      .bottom-content.justify-right
        img.h450(src='../static/slides/images/lecture09/fsm_doomguard.png')
      ul
        li also known as 
          span.highlight statecharts
        li each state can have a superstate or a substate
        li groups of states share transitions
        li usually implemented as a stack
          ul
            li push a low-level state on the stack when enter
            li pop and move to the next state when finished
      .tcenter
        img.h500(src='../static/slides/svg/lecture09/hfsm_guardian.svg')
    // ============================================================
    +mframeOrange(bgr, 'Behavior tree')
      ul
        li.highlight tree of hierarchical nodes that control decision making process
        li originate from gaming industry around 2004 (Halo 2)
        li combine elements from both Scripting and HFSMs
        li there is no standardized formalization
      ul
        li inner nodes lead to appropriate leaves best suited to the situation
        li depth-first traversal, starting with the root node
        li each executed behavior passes back and returns a status
          ul
            li.highlight.code SUCCESS, FAILURE, RUNNING, (SUSPENDED)
      .tcenter
        img.h400(src='../static/slides/images/lecture09/btree.jpg')
    // ============================================================
    +mframeOrange(bgr, 'Behavior tree')
      .tcenter
        img.h400(src='../static/slides/svg/lecture09/btree.svg')
      table.ml150
        tr
          th Node Type
          th Success
          th Failure
          th Running
        tr
          td Selector
          td If one child succeeds
          td If all children fail
          td If one child is running
        tr
          td Sequence
          td If all children succeed
          td If one child fails
          td If one child is running
        tr
          td Decorator
          td It depends...
          td It depends...
          td It depends...
        tr
          td Parallel
          td If N children succeed
          td If M-N children succeed
          td If all children are running
        tr
          td Action
          td When completed
          td Upon an error
          td During completion
        tr
          td Condition
          td If true
          td If false
          td Never
    // ============================================================
    +mframeGreen(bgr, 'Behavior tree node types')(class='space-vert-l')
      h4 Selector
      ul
        li tries to execute its child nodes from left to right until it receives a successful response
        li when a successful response is received, responds with a success
      h4 Sequence
      ul
        li will execute each of its child nodes in a sequence from left to right until a failure is received
        li if every child node responds with a success, the sequence node itself will respond with a success
      h4 Decorator
      ul
        li allows for additional behavior to be added without modifying code
        li only one child node
        li returns success if the specified condition is met and its subtree has been executed successfully
        li Example: 
          span.highlight-sec Repeater, Inventer, Succeeder, Failer, UntilFail, UntilSucceed
    // ============================================================
    +mframeGreen(bgr, 'Behavior tree node types')
      h4 Parallel node
      ul
        li a node that concurrently executes all of its children
      h4 Condition
      ul
        li a node that will observe the state of the game environment and respond with either a success or a failure based on the observation, condition etc.
        li
          span.highlight-sec Instant Check condition 
          | - the check is run once
        li
          span.highlight-sec Monitoring condition 
          | - keeps checking a condition over time
      h4 Action
      ul
        li a node used to interact with the game environment
        li may represent an atomic action, a script or even another BT
      h4 Blackboard
      ul
        li a construct that stores whatever information is written to it
        li any node inside or outside the tree has an access to the blackboard
        li.highlight-sec similar to GameModel attribute of component architecture's root node
    // ============================================================
    +mframe(bgr, 'Example: Unreal Engine BT Editor')
      .tcenter
        img.h850(src='../static/slides/images/lecture09/bt_unreal.jpg')
    // ============================================================
    +mframeGreen(bgr, 'Example: Warcraft Doomguard')
      .tcenter
        img.h800(src='../static/slides/svg/lecture09/btree_doomguard.svg')
    // ============================================================
    +mframeGreen(bgr, 'BT improvements')
      ul
        li let's define a conditional selector in order to simplify the diagram
      .tcenter
        img.h200(src='../static/slides/svg/lecture09/btree_improvement.svg')
      .tcenter
        img.h600(src='../static/slides/svg/lecture09/btree_doomguard_improved.svg')
    // ============================================================
    +mframeGreen(bgr, 'Example: Door opening')
      .top-content.justify-left.fill
        img.h500(src='../static/slides/images/lecture09/door_open.gif')
      .top-content.fill
        img.h700.mt200(src='../static/slides/svg/lecture09/btree_door_opening.svg')
    // ============================================================
    +chapter(bgr, 'Advanced AI techniques')
    // ============================================================
    +mframeOrange(bgr, 'Terms')
      h4 Bot
      ul
        li an intelligent artificial player emulating a human player
        li used mainly to describe AI in FPS game
      h4 NPC
      ul
        li non-playable character - doesn't play the game but rather interacts with the player
      h4 Planning
      ul
        li a formalized process of searching for sequence of actions to satisfy a 
          span.highlight-sec goal
      h4 Supervised learning
      ul
        li works just like learning at schools
        li for certain input there is a 
          span.highlight-sec correct output 
          | the algorithm has to learn
      h4 Unsupervised learning
      ul
        li the output cannot be categorized as being either correct or false
        li the algorithm learns 
          span.highlight-sec patterns 
          | instead
      h4 Reinforcement learning
      ul
        li an agent must learn the best possible output by using trial and error
        li for each action chosen the agent obtains a 
          span.highlight-sec feedback
    // ============================================================
    +mframeGreen(bgr, 'Challenges for Game AI')
      .top-content.justify-right.mt20
        img.h350(src='../static/slides/images/lecture09/ai_challenges.png')
      h4.mt20 Game AI features and limits
      ul
        li real-time
        li limited resources
        li incomplete knowledge
        li planning
        li learning
      h4 Game AI properties
      ul
        li predictability and unpredictability (surprise elements)
        li support - communication between NPC and a player
        li surprise - harassment, ambush, team support
        li.highlight winning well and losing well
        li cheating - acceptable as long as it doesn't get detected by the player
      .tcenter.highlight-third.mt40 We want it to be fun to play against, not beat us easily
    // ============================================================
    +mframe(bgr, 'Named AI techniques in games')(class='line-m')
      ul
        li
          +strtext('', 'Starcraft (1998)', '- particle model for hidden units\' position estimation')
        li
          +strtext('', 'Unreal Tournament (1999)', '- Bayesian Behaviors')
        li
          +strtext('', 'Quake III (1999)', '- HFSM for decisions, AAS (Area Awareness System) for collisions and pathfinding')
        li
          +strtext('', 'Halo 2 (2004)', '- Behavior Trees and Fuzzy Logic')
        li
          +strtext('', 'F.E.A.R. (2005)', '- GOAP (goal-oriented action planning)')
        li
          +strtext('', 'Arma (2006)', '- Hierarchical Task Networks (HTN) for mission generator')
        li
          +strtext('', 'Wargus (Warcraft II Clone)', '- Case-Based reasoning')
        li
          +strtext('', 'City Conquest (2011)', '- genetic algorithm used to tune dominant strategies')
        li
          +strtext('', 'Tomb Raider (2013)', '- advanced GOAP')
    // ============================================================
    +mframeGreen(bgr, 'AI Model')
      ul
        li.highlight AI model is just another representation of the game world
        li must be simple enough for the AI to process it in real-time and still complex enough <br> to produce a believable behavior
        li Mario could be controlled either by an evolutionary algorithm or just a simple script with pathfinding, enemy detection and the ability to jump over enemies
      .columns-3.mt40
        figure
          img.h400(src='../static/slides/images/lecture09/ai_model_view.jpg')
          p View Model
        figure
          img.h400(src='../static/slides/svg/lecture09/ai_model_physics.svg')
          p Physics Model
        figure
          img.h400(src='../static/slides/svg/lecture09/ai_model_ai.svg')
          p AI Model
    // ============================================================
    +mframeGreen(bgr, 'Predicting opponents')(class='line-sm')
      .bottom-content.justify-right.fill
        img.h450(src='../static/slides/images/lecture09/predicting_opponents.jpg')
      h4 Cheating bots are not fun in general
      ul
        li inhumanly accurate aim in shooting games, bots that know where you are,...
      h4 Partial observations of the game state
      ul
        li AI is informed in the same way as the human player
        li the mistakes these models make are more human-like
        li
          span.highlight-sec filtering problem 
          | - estimating the internal states based on partial observations
        li
          span.highlight-sec general approaches:
          ul
            li Hidden semi-markov model
            li Particle filters
        li
          span.highlight-sec approaches for FPS:
          ul
            li Occupancy map
            li SOAR cognitive architecture (used in Quake II)
            li Vision Code (used in Bioshock)
        li
          span.highlight-sec approaches for RTS:
          ul
            li Threat map
            li Influence map
            li Bayesian networks
    // ============================================================
    +mframeOrange(bgr, 'Occupancy map')
      ul
        li a grid over the game environment
        li maintains probability for each grid cell
        li probability represents the likelihood of an opponent presence
        li when the opponent is not visible, the probabilities from the previous occupancy cells are propagated along the edges to neighboring cells
      .tcenter
        img.h600(src='../static/slides/images/lecture09/occupancy_map.gif')
    // ============================================================
    +mframeOrange(bgr, 'Threat map')
      ul
        li used in RTS
        li the value at any coordinate is the damage that the enemy can inflict
        li updating is done through iterating the list of known enemies
        li can be easily integrated into pathfinding
      ul
        li
          span.highlight Example: 
          | combat units bypass enemy defensive structure in order to attack their infrastructure
      .tcenter 
        img.h600(src='../static/slides/svg/lecture09/threat_map.svg')
    // ============================================================
    +mframeOrange(bgr, 'Influence map')
      ul
        li more generalized than threat maps
        li helps the AI to make better decisions by providing useful information
          ul
            li situation summary (borders, enemy presence)
            li statistics summary (number of visits, number of assaults)
            li future predictions
        li
          span.highlight Example: 
          |number of units killed during last strike
      .tcenter
        img.h550(src='../static/slides/svg/lecture09/influence_map.svg') 
    // ============================================================
    +mframeGreen(bgr, 'Reinforcement learning')
      .bottom-content.justify-right
        img.h400.mb40.mr40(src='../static/slides/images/lecture09/reinforcement_learning.gif')
      ul
        li.highlight learning what to do and how to map states to actions to maximize a reward
        li based on its action, the agent gets a 
          span.highlight-sec reward 
          | or 
          span.highlight-sec punishment 
          | - these rewards are used to learn
        li
          span.highlight-sec Reward 
          |- informs the agent to which outcome the selected action leads
      h4 Algorithms
      ul
        li Genetic Evolution
        li Q-Learning
        li SARSA (State-Action-Reward-State-Action)
        li Simulated annealing
        li Monte-Carlo simulation
      h4 Models
      ul
        li Decision trees
        li Bayesian networks
        li Neural networks
    // ============================================================
    +mframeGreen(bgr, 'Artificial neural network')
      .bottom-content.justify-left
        img.h300(src='../static/slides/images/lecture09/neural_net_dragon.png')
      .bottom-content.justify-right
        img.w150.mb150.mr400(src='../static/slides/images/lecture09/neural_net_fireball.png')
      .bottom-content.justify-right
        img.w750(src='../static/slides/images/lecture09/neural_net_platform.png')
      .bottom-content.justify-right
        img.h150.mb70.mr200(src='../static/slides/images/lecture09/neural_net_mage.png')
      ul
        li computational model that attempts to simulate a biological neural network
        li network of nodes are connected by links that have numeric weights attached
        li 
          span.highlight backpropagation 
          |- measure of divergence between the observed and the desired output
      .tcenter
        img.h700(src='../static/slides/svg/lecture09/artificial_neural_network.svg')
    // ============================================================
    +mframeGreen(bgr, 'Neural network applications')
      .top-content.justify-right.mt100
        img.h400(src='../static/slides/images/lecture09/neural_network_mario.jpg')
      h4 MarI/O
      ul
        li NEAT - genetic algorithm for evolving neural networks
        li Input: simplified game screen (13x13 blocks)
        li Output: pressed button (6 neurons)
        li Max neurons: 1 000 000
      .tcenter
        img.h250(src='../static/slides/svg/lecture09/neural_network_mario.svg')
      h4 DeepMind 2014
      ul
        li neural network that can play Atari games (uses Q-learning)
        li Inputs: 210x160 RGB at 60Hz, terminal signal and game score
      .tcenter
        img.h200(src='../static/slides/images/lecture09/neural_network_atari.png')
    // ============================================================
    +mframeOrange(bgr, 'Goal-oriented action planning')
      ul
        li centers on the idea of goals as desirable world states
        li each action has a set of conditions it can satisfy, as well as a set of preconditions that <br>must be true in order to be satisfied
        li originally implemented for F.E.A.R (2005)
        li 
          span.highlight two stages: 
          |select a relevant goal and attempt to fulfill that goal
      .tcenter
        img.h600(src='../static/slides/svg/lecture09/goap.svg')
    // ============================================================
    +mframeGreen(bgr, 'Example: F.E.A.R.')
      ul
        li Advanced AI behavior: blind fire, dive through windows, take cover,...
        li
          span.highlight the key idea: 
          | to determine when to switch and what parameters to set
      .tcenter
        img.h700(src='../static/slides/images/lecture09/fear.jpg')
    // ============================================================
    +mframeGreen(bgr, 'Example: F.E.A.R.')
      .top-content.justify-left
        img.h150.mt200.ml600(src='../static/slides/images/lecture09/fear_soldier.png')
      .top-content.justify-left
        img.h150.mt200.ml1000(src='../static/slides/images/lecture09/fear_assassin.png')
      .top-content.justify-right
        img.w150.mt250.mr300(src='../static/slides/images/lecture09/fear_rat.png')
      ul
        li a set of goals is assigned to each NPC
        li these goals compete for activation, and the AI uses the planner to try to satisfy the highest priority goal
        li the AI figures out the dependencies at run-time based on the goal state and the preconditions and effects of actions
      table.flat.ml250
        tr
          th Soldier
          th Assassin
          th Rat
        tr
          td Attack
          td Attack
          td Animate
        tr
          td AttackCrouch
          td InspectDisturbance
          td Idle
        tr
          td SuppressionFire
          td LookAtDisturbance
          td GotoNode
        tr
          td SupressionFireFromCover
          td SurveyArea
          td UseSmartObjectNode
        tr
          td FlushOutWithGrenade
          td AttackMeleeUncloaked
          td
        tr
          td AttackFromCover
          td TraverseBlockedDoor
          td
        tr
          td BlindFireFromCover
          td AttackFromAmbush
          td
        tr
          td ReloadCovered
          td AttackLungeUncloaked
          td
    // ============================================================
    +chapter(bgr, 'AI in Real-time strategies')
    // ============================================================
    +mframeGreen(bgr, 'Real-time strategy')
      .bottom-content.justify-right
        img.h600.mb60.mr20(src='../static/slides/images/lecture09/rts.png')
      ul
        li Real-time strategy is a Bayesian, zero-sum game (Rubinstein, 1994)
        li A game where the player is in control of certain, usually military, assets, with which the player can manipulate in order to achieve victory
      h4 Main elements
      ul
        li map, mini-map
        li resources
        li units and their attributes
        li buildings
        li tech tree
      h4 Other features
      ul
        li real-time aspect (no turns)
        li fog of war
        li many strategies
        li game modes: campaign, skirmish, multiplayer
    // ============================================================
    +mframe(bgr, 'RTS games')
      .columns-3
        .tcenter
          img.h450.ml80(src='../static/slides/images/lecture09/rts_dune.png')
        .tcenter
          img.h450(src='../static/slides/images/lecture09/rts_redalert.png')
        .tcenter
          img.h450.mr80(src='../static/slides/images/lecture09/rts_total.png')
      .columns-3
        .tcenter
          img.h450.ml80(src='../static/slides/images/lecture09/rts_w3.png')
        .tcenter
          img.h450(src='../static/slides/images/lecture09/rts_starcraft.png')
        .tcenter
          img.h450.mr80(src='../static/slides/images/lecture09/rts_ashes.png')
    // ============================================================
    +mframeOrange(bgr, 'RTS features')(class='line-s')
      h4 Resource control
      ul
        li minerals, gas, oil, trees etc.
        li controlling more resources increases the players' construction capabilities
      h4 Tech tree
      ul
        li a directed acyclic graph that contains the whole technological development of a faction
      h4 Build order (opening)
      ul
        li the timings at which the first buildings are constructed
      h4 Fog of war
      ul
        li fog that covers the parts of the map the player has not yet explored
        li requires to scout unexplored areas to find enemy sources
      h4 Micromanagement
      ul
        li way of controlling units in detail while they are in combat
      h4 Tactics
      ul
        li a set of specific actions used when applying a strategy
      h4 Strategy
      ul
        li making decisions knowing what we saw from the opponent
        li we can prioritize economy over technology or military production
    // ============================================================
    +mframe(bgr, 'Example: Starcraft 2 tech-tree')
      .tcenter
        img.h900(src='../static/slides/images/lecture09/techtree_sc2.png')
    // ============================================================
    +mframe(bgr, 'RTS strategies')(class='line-sm')
      h4 Strategies
      ul
        li
          span.highlight-sec rush strategy
          ul
            li hurrying into one or more early attacks
        li
          span.highlight-sec countering strategy
          ul
            li surviving an attack and performing a counter-attack
        li
          span.highlight-sec siege
          ul
            li playing defensively, utilizing heavy weaponry and performing a set of massive attacks
        li
          span.highlight-sec tech strategy
          ul
            li spending resources in early game on enabling the player to construct more advanced combat units
      h4 Turtling
      ul
        li player that gets into a defensive position but is unable to expand
      h4 Scouting
      ul
        li sending units to places the player suspects there might be enemies and possible discovering their location and progress
    // ============================================================
    +mframeGreen(bgr, 'RTS AI layers')
      .top-content.mt150
        img.h700(src='../static/slides/svg/lecture09/rts_ai_layers.svg')
      ul
        li
          span.highlight Three layers (architectural perspective)
          ul
            li micromanagement
            li tactics (army positions)
            li strategy (tech tree)
    // ============================================================
    +mframeGreen(bgr, 'AI in real-time strategies')
      .bottom-content.justify-left
        img.h300.mb200.ml80(src='../static/slides/svg/lecture09/ai_in_rts_bot.svg')
      .bottom-content.justify-right
        img.h300.mb200.mr80(src='../static/slides/svg/lecture09/ai_in_rts_human.svg')
      ul
        li a goal in the development of an AI is to make the human player identify the computer opponent as an opposing player and not just a set of algorithms
        li in early games, AI attacked at intervals in small waves of units, emulating a sense of action
        li 
          span.highlight approaches: 
          |manager-based AI, layer-based AI, CBR, rule-based AI, reinforcement learning
      .tcenter
        img.h500.mt80(src='../static/slides/images/lecture09/ai_in_rts_map.png')
    // ============================================================
    +mframeGreen(bgr, 'Manager-based AI')(class='line-s')
      h4 Unit micromanagement AI
      ul
        li controls units that are in combat
      h4 Medium-level strategic AI
      ul
        li in control of 5-30 units
      h4 High-level strategic AI
      ul
        li overall strategy, determines a specific playing style
      h4 Worker unit AI
      ul
        li controls workers and their goals
      h4 Town building AI
      ul
        li builds a town/base in response to the tech tree
      h4 Opponent modelling AI
      ul
        li process of keeping track of what units the enemy builds
      h4 Resource management AI
      ul
        li manages gathering resources
      h4 Reconnaissance AI
      ul
        li finding out what is happening on the map
    // ============================================================
    +mframeGreen(bgr, 'Layer-based AI')
      ul
        li AI is built from multiple layers
        li each layer handles specific task
        li there can be lower-level and higher-level decision components
        li decision components consider available information, retrieved by lower components, to make decisions; executors are triggered afterwards
      ul
        li
          +strtext('', 'Sensor', '- reads the game state')
        li
          +strtext('', 'Analyzer', '- combines sensing data to form a coherent picture')
        li
          +strtext('', 'Memorizer', '- stores various types of data (terrain analysis, past decisions,...)')
        li
          +strtext('', 'Decider', '- a strategic decider, determines goals')
        li
          +strtext('', 'Executor', '- translates goals into actions')
        li
          +strtext('', 'Coordinator', '- synchronizes groups of units')
        li
          +strtext('', 'Actuator', '- executes actions by modifying the game state')  
      .tcenter
        img.h200(src='../static/slides/svg/lecture09/layer_based_ai.svg')
    // ============================================================
    +mframe(bgr, 'Example: Layer-based AI')
      .bottom-content.justify-right.fill
        img.h500(src='../static/slides/images/lecture09/layer_based_ai.png')
      .top-content
        img.h900.mr150(src='../static/slides/svg/lecture09/layer_based_ai_example.svg')
    // ============================================================
    +mframe(bgr, 'Example: Layer-based AI')
      .top-content.justify-right.fill
        img.h550(src='../static/slides/images/lecture09/layer_based_ai_cossacks.jpg')
      .top-content.justify-left
        img.h900(src='../static/slides/svg/lecture09/layer_based_ai_cossacks.svg')
    // ============================================================
    +mframeGreen(bgr, 'Case-based reasoning')
      h4 Main idea
      ul
        li when making decisions, we remember previous experiences and then reapply solutions that worked in previous situations
        li if a certain situation hasn't been encountered yet, we recall 
          span.highlight similar experience 
          |and then adjust the solution to fit the current situation
        li takes the current situation, compares it to a knowledge base of previous cases, selects the most similar one, adjusts it and updates the base
      h4 Steps
      ul
        li
          +strtext('', 'Retrieve', '- get the cases which are relevant to the given problem')
        li
          +strtext('', 'Reuse', '- create a preliminary solution from selected cases')
        li
          +strtext('', 'Revise', '- adapt the preliminary solution to fit the current situation')
        li
          +strtext('', 'Retain', '- save the case into the knowledge base')
    // ============================================================
    +mframeGreen(bgr, 'Example: Defcon')
      ul
        li multiplayer real-time strategy game
        li players compete in a nuclear war to score points by hitting opponent cities
        li stages: placing resources, fleet maneuvres, fighter attacks, final missile strikes
        li AI: decision tree learning and case-based reasoning
      .tcenter
        img.h600(src='../static/slides/images/lecture09/case_based_defcon.jpg')
    // ============================================================
    +mframeGreen(bgr, 'Defcon: Case structure')
      ul
        li starting positions of units and buildings
        li metafleet movement and attack plan
        li performance statistics for deployed resources
        li abstraction of the opponent attacks (time-frame clustering)
        li routes taken by opponent fleets
        li final scores of the two players
      .tcenter
        img.h550(src='../static/slides/svg/lecture09/case_based_reasoning.svg')
    // ============================================================
    +mframeGreen(bgr, 'Example: Megaglest')
      ul
        li open-source 3D RTS
        li seven factions: tech, magic, egypt, indians, norsemen, persian, romans
        li.highlight rule-based AI
      .tcenter
        figure
          img.h600(src='../static/slides/images/lecture09/case_based_megaglest.jpg')
          p
            a(href='https://github.com/MegaGlest/megaglest-source') LINK
    // ============================================================
    +mframe(bgr, 'Megaglest rules')
      table.line-s.ml150
        tr
          th Rule
          th Condition
          th Command
          th Freq [ms]
        tr
          td AiRuleWorkerHarvest
          td Worker stopped
          td Order worker to harvest
          td 2 000
        tr
          td AiRuleRefreshHarvester
          td Worker reassigned
          td
          td 20 000
        tr
          td AiRuleScoutPatrol
          td Base is table
          td Send scout patrol
          td 10 000
        tr
          td AiRuleRepair
          td Building Damaged
          td Repair
          td 10 000
        tr
          td AiRuleReturnBase
          td Stopped unit
          td Order return base
          td 5 000
        tr
          td AiRuleMassiveAttack
          td Enough soldiers
          td Order massive attack
          td 1 000
        tr
          td AiRuleAddTasks
          td Tasks empty
          td Add tasks
          td 5 000
        tr
          td AiRuleBuildOneFarm
          td Not enough farms
          td Build farm
          td 10 000
        tr
          td AiRuleResourceProducer
          td Not enough resources
          td Build resource producer
          td 5 000
        tr
          td AiRuleProduce
          td Performing prod. task
          td
          td 2 000
        tr
          td AiRuleBuild
          td Performing build task
          td
          td 2 000
        tr
          td AiRuleUpgrade
          td Performing upg. task
          td
          td  2 000
        tr
          td AiRuleExpand
          td Expanding
          td
          td 30 000
        tr
          td AiRuleUnBlock
          td Blocked units
          td Move surrounding units
          td 3 000
    // ============================================================
    +mframe(bgr, 'Lecture 9 summary')
      ul
        li
          +btext('', 'Navigation graph:', 'abstraction of all locations in a game environment')
          ul
            li waypoint-based, mesh-based, grid-based (tile, octile, hex)
        li
          +btext('', 'A*:', 'path-finding algorithm that uses an estimate of the cost to reach the target')
        li.mt40
          +btext('', 'FSM:', 'structure used to model a simple behavior')
          ul
            li each game entity can be in exactly one of a finite number of states at any time
        li
          +btext('', 'Behavior Tree:', 'tree of nodes that control a decision making process')
          ul
            li nodes: selector, sequence, parallel, decorator, action, condition
        li
          +btext('', 'Terms:', 'Bot, NPC, Planning, Supervised learning, Unsupervised learning, Reinforcement learning')
      ul.mt40
        li
          +btext('', 'GOAP:', 'centers on the idea of goals as desirable world states')
        li
          +btext('', 'RTS AI Layers:', 'micromanagement, tactics, strategy')
        li
          +btext('', 'Case-based reasoning:', 'finding solutions based on similar past solutions')
    // ============================================================

include ./partial/footer.pug
script(src!='../libs/revealjs/revealjs.ts')
script(src!='../src/lectures/reveal-setup.ts')
